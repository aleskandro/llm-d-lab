{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc130f8-a0a1-4793-82af-da974ee67082",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b1dfa01cf974e07",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import plotly.io as pio\n",
    "import urllib3\n",
    "import warnings\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "\n",
    "from data_source.prometheus import *\n",
    "from transform.sampling import *\n",
    "from plotting.load_signal_static import *\n",
    "from plotting.violin_plots import *\n",
    "from plotting.candlestick import *\n",
    "from plotting.combine import *\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# Configuration: $ oc port-forward -n openshift-monitoring svc/thanos-querier 9091:9091\n",
    "PROMETHEUS_URL = \"https://localhost:9091\"\n",
    "BEARER_TOKEN = \"\"\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B\"\n",
    "NAMESPACE = \"experiment-01\"\n",
    "\n",
    "TIME_RANGES = [\n",
    "    (datetime(2025, 12, 19, 12, 20), datetime(2025, 12, 19, 13, 20), \"WVA\"),\n",
    "    (datetime(2025, 12, 19, 12, 50), datetime(2025, 12, 19, 13, 20), \"1 Replica\"),\n",
    "]\n",
    "OUTPUT_FOLDER = Path(\"_out/refactoring\")\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "QUERY = False\n",
    "STORE = True # Will store queried data to avoid re-querying (needs QUERY=True first) - Ignored when LOAD=True, QUERY=False\n",
    "LOAD = True\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not (QUERY or LOAD):\n",
    "    raise ValueError(\"Either QUERY or LOAD must be True.\")"
   ],
   "id": "6e978099c8cdbc94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "cell_type": "code",
   "source": [
    "if QUERY:\n",
    "    prom = PrometheusConnect(\n",
    "        url=PROMETHEUS_URL,\n",
    "        disable_ssl=True,\n",
    "        headers={\"Authorization\": f\"Bearer {BEARER_TOKEN}\"},\n",
    "    )"
   ],
   "id": "280743cb96a56a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if QUERY:\n",
    "    e2e_aggregated = custom_query_range_by_run(prom, TIME_RANGES, 'sum by(le) (rate(vllm:e2e_request_latency_seconds_bucket{{model_name=\"{m}\",namespace=\"{ns}\"}}[1m]))'.format(m=MODEL_NAME, ns=NAMESPACE), \"1m\", histogram_to_samples_global)\n",
    "    itl_aggregated = custom_query_range_by_run(prom, TIME_RANGES, 'sum by(le) (rate(vllm:inter_token_latency_seconds_bucket{{model_name=\"{m}\",namespace=\"{ns}\"}}[1m]))'.format(m=MODEL_NAME, ns=NAMESPACE), \"1m\", histogram_to_samples_global)\n",
    "    ttft_aggregated = custom_query_range_by_run(prom, TIME_RANGES, 'sum by(le) (rate(vllm:time_to_first_token_seconds_bucket{{model_name=\"{m}\",namespace=\"{ns}\"}}[1m]))'.format(m=MODEL_NAME, ns=NAMESPACE), \"1m\", histogram_to_samples_global)\n",
    "    kvcache_aggregated = custom_query_range_by_run(prom, TIME_RANGES, 'avg(vllm:kv_cache_usage_perc{{model_name=\"{m}\",namespace=\"{ns}\"}})'.format(m=MODEL_NAME, ns=NAMESPACE), \"1m\", samples_generator_flat)\n",
    "    queue_size_aggregated = custom_query_range_by_run(prom, TIME_RANGES, 'sum(vllm:num_requests_waiting{{model_name=\"{m}\",namespace=\"{ns}\"}})'.format(m=MODEL_NAME, ns=NAMESPACE), \"1m\", samples_generator_flat)\n",
    "    if STORE:\n",
    "        e2e_aggregated.to_parquet(OUTPUT_FOLDER / f\"e2e_aggregated.parquet\")\n",
    "        itl_aggregated.to_parquet(OUTPUT_FOLDER / f\"itl_aggregated.parquet\")\n",
    "        ttft_aggregated.to_parquet(OUTPUT_FOLDER / f\"ttft_aggregated.parquet\")\n",
    "        kvcache_aggregated.to_parquet(OUTPUT_FOLDER / f\"kvcache_aggregated.parquet\")\n",
    "        queue_size_aggregated.to_parquet(OUTPUT_FOLDER / f\"queue_size_aggregated.parquet\")\n",
    "\n",
    "if LOAD:\n",
    "    e2e_aggregated = pd.read_parquet(OUTPUT_FOLDER / f\"e2e_aggregated.parquet\")\n",
    "    itl_aggregated = pd.read_parquet(OUTPUT_FOLDER / f\"itl_aggregated.parquet\")\n",
    "    ttft_aggregated = pd.read_parquet(OUTPUT_FOLDER / f\"ttft_aggregated.parquet\")\n",
    "    kvcache_aggregated = pd.read_parquet(OUTPUT_FOLDER / f\"kvcache_aggregated.parquet\")\n",
    "    queue_size_aggregated = pd.read_parquet(OUTPUT_FOLDER / f\"queue_size_aggregated.parquet\")\n"
   ],
   "id": "e77d76673939f71c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if QUERY:\n",
    "    metrics = {\n",
    "        \"ITL\": \"vllm:inter_token_latency_seconds_bucket\",\n",
    "        \"E2E\": \"vllm:e2e_request_latency_seconds_bucket\",\n",
    "        \"TTFT\": \"vllm:time_to_first_token_seconds_bucket\",\n",
    "    }\n",
    "    latency_df = get_histograms_p_tables_by_run(prom, TIME_RANGES, metrics, MODEL_NAME, NAMESPACE)\n",
    "\n",
    "    if STORE:\n",
    "        latency_df.to_parquet(OUTPUT_FOLDER / f\"latency_df.parquet\")\n",
    "\n",
    "if LOAD:\n",
    "    latency_df = pd.read_parquet(OUTPUT_FOLDER / f\"latency_df.parquet\")"
   ],
   "id": "b5aa50745f9f3a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c43edc3975bfbc8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "if QUERY:\n",
    "    gauge_metrics = {\n",
    "        \"KV Cache Util.\": \"avg(vllm:kv_cache_usage_perc)\",\n",
    "        \"Queued Requests\": (\n",
    "            'sum(vllm:num_requests_waiting{{model_name=\"{m}\",namespace=\"{ns}\"}})'\n",
    "            .format(m=MODEL_NAME, ns=NAMESPACE)\n",
    "        ),\n",
    "        \"Power\": 'sum(DCGM_FI_DEV_POWER_USAGE{{exported_namespace=~\"{ns}\"}})'.format(ns=NAMESPACE)\n",
    "    }\n",
    "    other_df = get_gauge_p_tables_by_run(prom, TIME_RANGES, gauge_metrics)\n",
    "\n",
    "    if STORE:\n",
    "        other_df.to_parquet(OUTPUT_FOLDER / f\"other_df.parquet\")\n",
    "\n",
    "if LOAD:\n",
    "    other_df = pd.read_parquet(OUTPUT_FOLDER / f\"other_df.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if QUERY:\n",
    "    ttft_candlestick_results = compare_runs_quantiles_for_metric(\n",
    "        _prom=prom,\n",
    "        time_ranges=TIME_RANGES,\n",
    "        model_name=MODEL_NAME,\n",
    "        namespace=NAMESPACE,\n",
    "        variant_name=\"ms-inference-scheduling-llm-d-modelservice-decode\",\n",
    "        metric_name=\"vllm:time_to_first_token_seconds\",\n",
    "        iqr_step=\"5m\",\n",
    "        iqr_rate_interval=\"5m\",\n",
    "        p50_step=\"10s\",\n",
    "        p50_rate_interval=\"1m\",\n",
    "    )\n",
    "\n",
    "    e2e_candlestick_results = compare_runs_quantiles_for_metric(\n",
    "        _prom=prom,\n",
    "        time_ranges=TIME_RANGES,\n",
    "        model_name=MODEL_NAME,\n",
    "        namespace=NAMESPACE,\n",
    "        variant_name=\"ms-inference-scheduling-llm-d-modelservice-decode\",\n",
    "        metric_name=\"vllm:e2e_request_latency_seconds\",\n",
    "        iqr_step=\"5m\",\n",
    "        iqr_rate_interval=\"5m\",\n",
    "        p50_step=\"10s\",\n",
    "        p50_rate_interval=\"1m\",\n",
    "    )\n",
    "\n",
    "    itl_candlestick_results = compare_runs_quantiles_for_metric(\n",
    "        _prom=prom,\n",
    "        time_ranges=TIME_RANGES,\n",
    "        model_name=MODEL_NAME,\n",
    "        namespace=NAMESPACE,\n",
    "        variant_name=\"ms-inference-scheduling-llm-d-modelservice-decode\",\n",
    "        metric_name=\"vllm:inter_token_latency_seconds\",\n",
    "        iqr_step=\"5m\",\n",
    "        iqr_rate_interval=\"5m\",\n",
    "        p50_step=\"10s\",\n",
    "        p50_rate_interval=\"1m\",\n",
    "        values_scale_func=lambda x: x * 1e3,\n",
    "    )\n",
    "\n",
    "    if STORE:\n",
    "        with open(OUTPUT_FOLDER / \"ttft_candlestick_results.pkl\", \"wb\") as f:\n",
    "            pickle.dump(ttft_candlestick_results, f)\n",
    "\n",
    "        with open(OUTPUT_FOLDER / \"e2e_candlestick_results.pkl\", \"wb\") as f:\n",
    "            pickle.dump(e2e_candlestick_results, f)\n",
    "\n",
    "        with open(OUTPUT_FOLDER / \"itl_candlestick_results.pkl\", \"wb\") as f:\n",
    "            pickle.dump(itl_candlestick_results, f)\n",
    "\n",
    "        # Also store the dataframes\n",
    "        for name, dfs in [\n",
    "            (\"ttft_candlestick_df\", ttft_candlestick_results),\n",
    "            (\"e2e_candlestick_df\", e2e_candlestick_results),\n",
    "            (\"itl_candlestick_df\", itl_candlestick_results),\n",
    "        ]:\n",
    "            for run, dfs in dfs.items():\n",
    "                df, scaling_actions = dfs\n",
    "                df.to_parquet(OUTPUT_FOLDER / f\"{name}_{run}_data.parquet\")\n",
    "                scaling_actions.to_parquet(OUTPUT_FOLDER / f\"{name}_{run}_scaling_actions.parquet\")\n",
    "\n",
    "\n",
    "if LOAD:\n",
    "    with open(OUTPUT_FOLDER / \"ttft_candlestick_results.pkl\", \"rb\") as f:\n",
    "        ttft_candlestick_results = pickle.load(f)\n",
    "\n",
    "    with open(OUTPUT_FOLDER / \"e2e_candlestick_results.pkl\", \"rb\") as f:\n",
    "        e2e_candlestick_results = pickle.load(f)\n",
    "\n",
    "    with open(OUTPUT_FOLDER / \"itl_candlestick_results.pkl\", \"rb\") as f:\n",
    "        itl_candlestick_results = pickle.load(f)\n"
   ],
   "id": "b948530d34f57feb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "cell_type": "markdown",
   "source": "## Plotting",
   "id": "7b54be6836e59dfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from plotting.tables import *\n",
    "\n",
    "metric_scale = {\n",
    "    \"ITL\": 1e3,\n",
    "    \"KV Cache Util.\": 1e2,\n",
    "    \"Energy\": 1e-3,\n",
    "    \"Power\": 1e-3,\n",
    "\n",
    "}\n",
    "\n",
    "metric_unit = {\n",
    "    \"ITL\": \"ms\",\n",
    "    \"KV Cache Util.\": \"%\",\n",
    "    \"Queued Requests\": \"\",\n",
    "    \"Power\": \"kW\",\n",
    "    \"Energy\": \"kWh\"\n",
    "}\n",
    "\n",
    "order = [ x[2] for x in TIME_RANGES ]\n"
   ],
   "id": "47901ef2b44ddc17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "display(\n",
    "    add_metric_separators(\n",
    "        format_with_units_per_run_metric(\n",
    "            with_relative_change(\n",
    "                sort(latency_df, order), baseline_key=\"WVA\"\n",
    "            ),\n",
    "            metric_scale=metric_scale,\n",
    "            metric_unit=metric_unit,\n",
    "            baseline_key=\"WVA\"\n",
    "        )\n",
    "    ).hide(axis='index')\n",
    ")"
   ],
   "id": "6b655cd3a8ad2ead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "display(\n",
    "    add_metric_separators(\n",
    "        format_with_units_per_run_metric(\n",
    "            with_relative_change(\n",
    "                sort(other_df, order), baseline_key=\"WVA\"),\n",
    "            metric_scale=metric_scale,\n",
    "            metric_unit=metric_unit,\n",
    "            baseline_key=\"WVA\"\n",
    "        )\n",
    "    ).hide(axis='index')\n",
    ")\n"
   ],
   "id": "3e25390539fa7855",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "e2e_violin = violin_plot_by_run(\n",
    "    df=e2e_aggregated,\n",
    "    title=\"End-to-End Latency (E2E)\",\n",
    "    yscale=1,\n",
    "    xtitle=\"Scenario\",\n",
    "    yaxes_config=dict(\n",
    "        title=\"E2E Request Latency (s)\",\n",
    "        ticksuffix=\"s\",\n",
    "        tickformat=\".0f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "e2e_violin.show()"
   ],
   "id": "2a5653f6554b4919",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "itl_violin = violin_plot_by_run(\n",
    "    df=itl_aggregated,\n",
    "    title=\"Inter-Token Latency (ITL)\",\n",
    "    yscale=1e3,\n",
    "    xtitle=\"Scenario\",\n",
    "    yaxes_config=dict(\n",
    "        title=\"Inter-Token Latency (ms)\",\n",
    "        ticksuffix=\"ms\",\n",
    "        tickformat=\".0f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "itl_violin.show()"
   ],
   "id": "50908212bbfab789",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "ttft_violin = violin_plot_by_run(\n",
    "    df=ttft_aggregated,\n",
    "    title=\"Time-to-First-Token (TTFT)\",\n",
    "    yscale=1,\n",
    "    xtitle=\"Scenario\",\n",
    "    yaxes_config=dict(\n",
    "        title=\"Time to First Token (s)\",\n",
    "        ticksuffix=\"s\",\n",
    "        tickformat=\".0f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ttft_violin.show()"
   ],
   "id": "138a49801b67c41c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "kvcache_violin = violin_plot_by_run(\n",
    "    df=kvcache_aggregated,\n",
    "    title=\"KV Cache Utilization\",\n",
    "    yscale=100,\n",
    "    xtitle=\"Scenario\",\n",
    "    yaxes_config=dict(\n",
    "        title=\"KV Cache Utilization (%)\",\n",
    "        ticksuffix=\"%\",\n",
    "        tickformat=\".0f\"\n",
    "    )\n",
    ")\n",
    "\n",
    "kvcache_violin.show()"
   ],
   "id": "eeb87392db6e067f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "queue_size_violin = violin_plot_by_run(\n",
    "    df=queue_size_aggregated,\n",
    "    title=\"Queued Requests\",\n",
    "    yscale=1,\n",
    "    xtitle=\"Scenario\",\n",
    "    yaxes_config=dict(\n",
    "        title=\"Number of Queued Requests\",\n",
    "    )\n",
    ")\n",
    "\n",
    "queue_size_violin.show()"
   ],
   "id": "537c348eb6dfa925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ttft_candlesticks = candlesticks_over_time_with_scaling(\n",
    "    data=ttft_candlestick_results,\n",
    "    title=\"Time-To-First-Token (TTFT)\",\n",
    "    yaxis_title=\"TTFT (s)\",\n",
    "    y_unit=\"s\",\n",
    ")\n",
    "\n",
    "for fig in ttft_candlesticks.values():\n",
    "    fig.show()\n",
    "\n",
    "candlesticks_over_time_with_scaling_subplots(\n",
    "    data=ttft_candlestick_results,\n",
    "    title=\"Time-To-First-Token (TTFT) - Subplots\",\n",
    "    yaxis_title=\"TTFT (s)\",\n",
    "    y_unit=\"s\",\n",
    ").show()\n"
   ],
   "id": "a32300cec235717e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "e2e_candlesticks = candlesticks_over_time_with_scaling(\n",
    "    data=e2e_candlestick_results,\n",
    "    title=\"E2E Request Latency (E2E)\",\n",
    "    yaxis_title=\"E2E (s)\",\n",
    "    y_unit=\"s\",\n",
    ")\n",
    "\n",
    "candlesticks_over_time_with_scaling_subplots(\n",
    "    data=e2e_candlestick_results,\n",
    "    title=\"E2E Request Latency (E2E) - Subplots\",\n",
    "    yaxis_title=\"E2E (s)\",\n",
    "    y_unit=\"s\",\n",
    ").show()\n",
    "\n",
    "for fig in e2e_candlesticks.values():\n",
    "    fig.show()"
   ],
   "id": "3d94b809572ab4af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "itl_candlesticks = candlesticks_over_time_with_scaling(\n",
    "    data=itl_candlestick_results,\n",
    "    title=\"Inter-Token Latency (ITL)\",\n",
    "    yaxis_title=\"ITL (ms)\",\n",
    "    y_unit=\"ms\",\n",
    ")\n",
    "\n",
    "candlesticks_over_time_with_scaling_subplots(\n",
    "    data=itl_candlestick_results,\n",
    "    title=\"Inter-Token Latency (ITL) - Subplots\",\n",
    "    yaxis_title=\"ITL (ms)\",\n",
    "    y_unit=\"ms\",\n",
    ").show()\n",
    "\n",
    "for fig in itl_candlesticks.values():\n",
    "    fig.show()\n"
   ],
   "id": "2d7c4e1a1cb2c0a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
