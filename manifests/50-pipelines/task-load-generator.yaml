apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: guidellm-load-generator
  namespace: pipelines
spec:
  params:
    - name: target-url
      type: string
      description: The target URL for the benchmark
      default: "http://vllm:8000"
    - name: model
      type: string
      description: The model to benchmark
      default: "unsloth/Meta-Llama-3.1-8B"
    - name: rate-type
      type: string
      description: Rate type (synchronous, throughput, poisson, constant)
      default: ""
    - name: rate
      type: string
      description: Rate for constant/poisson modes (requests per second)
      default: ""
    - name: max-concurrency
      type: string
      description: Maximum concurrency (for throughput mode)
      default: ""
    - name: prompt-tokens
      type: string
      description: Number of prompt tokens
      default: ""
    - name: output-tokens
      type: string
      description: Number of output tokens
      default: ""
    - name: max-seconds
      type: string
      description: Maximum duration for the benchmark in seconds
      default: ""
    - name: max-requests
      type: string
      description: Maximum number of requests (alternative to max-seconds, leave empty to use max-seconds)
      default: ""
    - name: data-type
      type: string
      description: Data generation type (emulated, file, or custom token counts)
      default: ""
    - name: data-path
      type: string
      description: Path to data file if data-type is 'file'
      default: ""
    - name: output-basename
      type: string
      description: Base name for output files (e.g., 'my-benchmark' creates 'my-benchmark.json' and 'my-benchmark-log.txt')
      default: "benchmark"
    - name: hf-secret-name
      type: string
      description: Name of the secret containing HuggingFace token
      default: "huggingface-secret"
    - name: additional-args
      type: string
      description: Additional guidellm arguments (space-separated)
      default: ""
    - name: start-delay
      type: string
      description: Delay before starting the benchmark in seconds
      default: "0"
    - name: basepath
      type: string
      description: Base path for storing results
      default: ""
    - name: scenario
      type: string
      description: Scenario config for the benchmark (yaml encoded as a string)
      default: ""
    - name: test-name
      type: string
      description: Name of the test run
      default: "guidellm-benchmark"
  results:
    - name: benchmark-report
      description: Path to the benchmark JSON report
      type: string
    - name: log-file
      description: Path to the benchmark log file
      type: string
    - name: start-time
      description: Benchmark start time
      type: string
    - name: end-time
      description: Benchmark end time
      type: string
  workspaces:
    - name: results
      description: Workspace to store benchmark results and logs
  steps:
    - name: start-delay
      image: ghcr.io/vllm-project/guidellm:latest
      computeResources:
        requests:
          memory: "32Mi"
          cpu: "10m"
        limits:
          memory: "64Mi"
      imagePullPolicy: IfNotPresent
      script: |
        #!/bin/bash
        set -e
        if [ -n "$(params.start-delay)" ] && [ "$(params.start-delay)" -gt 0 ]; then
          echo "Waiting for $(params.start-delay) before starting the benchmark..."
          sleep $(params.start-delay)
          echo "Delay complete. Proceeding to benchmark."
          exit 0
        fi
        echo "No start delay specified. Proceeding."
    - name: label-this-pod
      computeResources:
        requests:
          memory: "32Mi"
          cpu: "10m"
        limits:
          memory: "64Mi"
      image: ghcr.io/helmfile/helmfile:v1.2.2
      script: |
          #!/bin/bash
          set -ex
          NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
          echo "Labeling pod $HOSTNAME in namespace $NAMESPACE"
          kubectl label pod $HOSTNAME benchmark-running=true -n $NAMESPACE --overwrite
          kubectl label pod $HOSTNAME benchmark-test-name="$(params.test-name)" -n $NAMESPACE --overwrite
    - name: run-benchmark
      image: ghcr.io/vllm-project/guidellm:latest
      imagePullPolicy: IfNotPresent
      computeResources:
        requests:
          memory: "128Mi"
          cpu: "1"
      env:
        - name: HF_HOME
          value: "/tmp"
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: $(params.hf-secret-name)
              key: token
              optional: true
      script: |
        #!/bin/bash
        set -e
        start_time=$(date --iso-8601=seconds --utc)
        random_uid=$(cat /proc/sys/kernel/random/uuid)
        base_path="$(params.basepath)"
        base_path="${base_path:-$(context.taskRun.name)}"
        folder_name="$(workspaces.results.path)/${base_path}/benchmark-${start_time}-$random_uid"
        mkdir -p "$folder_name"
        OUTPUT_JSON="${folder_name}/$(params.output-basename).json"
        OUTPUT_LOG="${folder_name}/$(params.output-basename)-log.txt"

        echo "Running $(params.rate-type) benchmark..."
        echo "Target: $(params.target-url)"
        echo "Model: $(params.model)"
        echo "Rate type: $(params.rate-type)"
      
        if [ -n "$(params.max-concurrency)" ]; then
          echo "Max concurrency: $(params.max-concurrency)"
          export GUIDELLM__MAX_CONCURRENCY=$(params.max-concurrency) 
        fi
        # Build the guidellm command
        CMD="/opt/app-root/bin/guidellm benchmark"
        if [ -n "$(params.scenario)" ]; then
          echo "$(params.scenario)" > /tmp/scenario.yaml
          CMD="$CMD --scenario /tmp/scenario.yaml"
          echo "Using scenario configuration."
        fi
        if [ -n "$(params.target-url)" ]; then
          CMD="$CMD --target $(params.target-url)"
          echo "Target URL: $(params.target-url)"
        fi
        if [ -n "$(params.rate-type)" ]; then
          CMD="$CMD --rate-type $(params.rate-type)"
          echo "Rate type: $(params.rate-type)"
        fi
        if [ -n "$(params.model)" ]; then
          CMD="$CMD --model $(params.model)"
          echo "Model: $(params.model)"
        fi

        # Add rate if specified (for poisson/constant modes)
        if [ -n "$(params.rate)" ]; then
          CMD="$CMD --rate $(params.rate)"
          echo "Rate: $(params.rate) req/s"
        fi

        # Add duration or request count
        if [ -n "$(params.max-requests)" ]; then
          CMD="$CMD --max-number $(params.max-requests)"
          echo "Max requests: $(params.max-requests)"
        else
          CMD="$CMD --max-seconds $(params.max-seconds)"
          echo "Max duration: $(params.max-seconds) seconds"
        fi

        # Add data configuration
        if [ "$(params.data-type)" = "file" ] && [ -n "$(params.data-path)" ]; then
          CMD="$CMD --data-type file --data $(params.data-path)"
          echo "Data: file at $(params.data-path)"
        fi
        
        if [ -n "$(params.prompt-tokens)" ] && [ -n "$(params.output-tokens)" ]; then
          CMD="$CMD --data prompt_tokens=$(params.prompt-tokens),output_tokens=$(params.output-tokens)"
          echo "Data: prompt_tokens=$(params.prompt-tokens), output_tokens=$(params.output-tokens)"
        fi

        # Add output path
        CMD="$CMD --output-path /tmp/benchmarks.json --disable-progress"

        # Add any additional arguments
        if [ -n "$(params.additional-args)" ]; then
          CMD="$CMD $(params.additional-args)"
          echo "Additional args: $(params.additional-args)"
        fi

        echo ""
        echo "Command: $CMD"
        echo ""

        # Run the benchmark and capture logs
        eval $CMD 2>&1 | tee "$OUTPUT_LOG"
        end_time=$(date --iso-8601=seconds --utc)
        
        # Copy results to workspace with specified basename
        cp /tmp/benchmarks.json "$OUTPUT_JSON"
        echo ""
        echo "Benchmark completed. Results saved to workspace."
        echo "  Report: $OUTPUT_JSON"
        echo "  Logs: $OUTPUT_LOG"

        # Emit results for artifacts
        echo -n "$OUTPUT_JSON" > $(results.benchmark-report.path)
        echo -n "$OUTPUT_LOG" > $(results.log-file.path)
        echo -n "$start_time" > $(results.start-time.path)
        echo -n "$end_time" > $(results.end-time.path)
